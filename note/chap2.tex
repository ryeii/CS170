\section{Divide-and-conquer Algorithms}

\subsection{Multiplication}

\begin{definition}[Integer Multiplication]
A divide-and-conquer algorithm for integer multiplication is defined as follows:
\begin{lstlisting}[mathescape=true, language=Octave]
function mul(x(0b[1...k]), y(0b[1...h]))
%Input: Positive integers x, y in binary
%Output: x times y

n = $\max$(size of x, size of y)
if n == 1: return $x\times y$

$x_L$, $x_R$ = x(0b[1...$\lceil n/2\rceil$]), x(0b[$\lfloor n/2\rfloor$...n])
$y_L$, $y_R$ = y(0b[1...$\lceil n/2\rceil$]), y(0b[$\lfloor n/2\rfloor$...n])

$P_1 = mul(x_L, y_L)$
$P_2 = mul(x_R, y_R)$
$P_3 = mul(x_L+x_R, y_L+y_R)$
return $P_1\times 2^n + (P_3-P_1-P_2)\times 2^{n/2}+P_2$
\end{lstlisting}
Where $0b[1...k]$ denotes the binary string representing a number.
\end{definition}
Each call of \textit{mul} has three recursive calls, inputs of which are half the size of the original inputs, and the base cases (x times y) take constant time. Therefore we conclude that the time taken by this algorithm is
\[
T(n) = 3T(n/2)+O(n)
\]
Apply the Master Algorithm in Chap 2.b, we conclude that the time complexity of this algorithm is
\[
T(n) \in O(n^{\log_23}) \approx O(n^{1.585})
\]

\subsection{Recurrence Relations}

\begin{theorem}[Master Algorithm]
If $T(n) = aT(n/b) + cn^k$ and $T(1) = c$ for some constants $a$, $b$, $c$ and $k$, then
\begin{equation*}
T(n) \in \begin{cases}
O(n^k) &if a<b^k \\
O(n^k\log n) &if a=b^k \\
O(n^{\log_ba}) &if a>b^k
\end{cases}
\end{equation*}
\end{theorem}

\subsection{Mergesort}

\begin{definition}[Mergesort]
The Mergesort algorithm is defined as follows:
\begin{lstlisting}[mathescape=true, language=Octave]
function mergesort(a[1...n])
	%Input: An array of numbers a[1...n]
	%Output: Sorted array a

	if n>1:
		return merge(mergesort(a[1...$\lfloor n/2 \rfloor$]), mergesort(a[$\lfloor n/2 \rfloor$+1...n]))
	else:
		return a

function merge(x[1...k], y[1...h])
	%Input: Two arrays of numbers (x[1...k], y[1...h])
	%Output: An array of numbers in x and y in ascending order

	if k=0: return y
	if l=0: return x
	if x[1] <= y[1]:
		return x[1] $\circ$ merge(x[2...k], y[1...h])
	else:
		return y[1] $\circ$ merge(x[1...k], y[2...h])
\end{lstlisting}
Where $\circ$ denotes concatenation.
\end{definition}

The \textit{merge} function above does a constant amount of work (concatenating two arrays) per recursive call, for a total running time of $O(k + h)$. Thus the calls to \textit{merge} in \textit{mergesort} are linear, we conclude that the overall time taken by \textit{mergesort} is
\[
T(n) = 2T(n/2) + O(n)
\]
Recall the Master Algorithm in Chap 2.b, we conclude that the time complexity of this algorithm is
\[
T(n) \in O(n\log n)
\]

\subsection{Medians}

\begin{definition}[selection]
A randomized divide-and-conquer algorithm for selection is defined as follows

\end{definition}

\subsection{Matrix Mltiplication}

\begin{definition}

\end{definition}

\subsection{Fast Fourier Transform}